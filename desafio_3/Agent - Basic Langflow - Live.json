{"id":"a321da40-0539-4330-b4e1-bb3db526b92e","data":{"nodes":[{"id":"ToolCallingAgent-G6W7l","type":"genericNode","position":{"x":1088.8798428950029,"y":-675.3752495472434},"data":{"type":"ToolCallingAgent","node":{"template":{"_type":"Component","chat_history":{"trace_as_input":true,"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"value":"","name":"chat_history","display_name":"Chat History","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"DataInput"},"llm":{"trace_as_metadata":true,"list":false,"required":true,"placeholder":"","show":true,"value":"","name":"llm","display_name":"Language Model","advanced":false,"input_types":["LanguageModel"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"HandleInput"},"tools":{"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"value":"","name":"tools","display_name":"Tools","advanced":false,"input_types":["Tool","BaseTool"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"HandleInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, List\n\nfrom langchain.agents import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.inputs import MultilineInput\nfrom langflow.inputs.inputs import HandleInput, DataInput\nfrom langflow.schema import Data\n\n\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"Agent that uses tools\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent\"\n\n    inputs = LCToolsAgentComponent._base_inputs + [\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> Optional[List[Data]]:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_tool_calling_agent(self.llm, self.tools, prompt)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"handle_parsing_errors":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"handle_parsing_errors","display_name":"Handle Parse Errors","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool","_input_type":"BoolInput"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"max_iterations":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"15","name":"max_iterations","display_name":"Max Iterations","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"int","_input_type":"IntInput"},"system_prompt":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"system_prompt","display_name":"System Prompt","advanced":false,"input_types":["Message"],"dynamic":false,"info":"System prompt for the agent.","title_case":false,"type":"str","_input_type":"MultilineInput"},"user_prompt":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{input}","name":"user_prompt","display_name":"Prompt","advanced":true,"input_types":["Message"],"dynamic":false,"info":"This prompt must contain 'input' key.","title_case":false,"type":"str","_input_type":"MultilineInput"},"verbose":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"verbose","display_name":"Verbose","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Agent that uses tools","icon":"LangChain","base_classes":["AgentExecutor","Message"],"display_name":"Tool Calling Agent","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["AgentExecutor"],"selected":"AgentExecutor","name":"agent","display_name":"Agent","method":"build_agent","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["Message"],"selected":"Message","name":"response","display_name":"Response","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","handle_parsing_errors","verbose","max_iterations","tools","llm","system_prompt","user_prompt","chat_history"],"beta":true,"edited":false,"lf_version":"1.0.14"},"id":"ToolCallingAgent-G6W7l"},"selected":false,"width":384,"height":610,"positionAbsolute":{"x":1088.8798428950029,"y":-675.3752495472434},"dragging":false},{"id":"ChatInput-zVfXN","type":"genericNode","position":{"x":-345.9929081964505,"y":-552.513851643801},"data":{"type":"ChatInput","node":{"template":{"_type":"Component","files":{"trace_as_metadata":true,"file_path":"","fileTypes":["txt","md","mdx","csv","json","yaml","yml","xml","html","htm","pdf","docx","py","sh","sql","js","ts","tsx","jpg","jpeg","png","bmp","image"],"list":true,"required":false,"placeholder":"","show":true,"value":"","name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","title_case":false,"type":"file","_input_type":"FileInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.memory import store_message\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"Research what is https://docs.langflow.org, then look into the docs to understand how to set it up Langwatch in Langflow","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Message to be passed as input.","title_case":false,"type":"str","_input_type":"MultilineInput"},"sender":{"trace_as_metadata":true,"options":["Machine","User"],"combobox":false,"required":false,"placeholder":"","show":true,"value":"User","name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Type of sender.","title_case":false,"type":"str","_input_type":"DropdownInput"},"sender_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"User","name":"sender_name","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Name of the sender.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"session_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"session_id","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"should_store_message":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"should_store_message","display_name":"Store Messages","advanced":true,"dynamic":false,"info":"Store the message in the history.","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["Message"],"display_name":"Chat Input","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"message","display_name":"Message","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","should_store_message","sender","sender_name","session_id","files"],"beta":false,"edited":false,"lf_version":"1.0.14"},"id":"ChatInput-zVfXN"},"selected":false,"width":384,"height":294,"positionAbsolute":{"x":-345.9929081964505,"y":-552.513851643801},"dragging":false},{"id":"ChatOutput-C4hM5","type":"genericNode","position":{"x":1542.131014501705,"y":-399.3944410479402},"data":{"type":"ChatOutput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.memory import store_message\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_AI\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"data_template":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{text}","name":"data_template","display_name":"Data Template","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Message to be passed as output.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"sender":{"trace_as_metadata":true,"options":["Machine","User"],"combobox":false,"required":false,"placeholder":"","show":true,"value":"Machine","name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Type of sender.","title_case":false,"type":"str","_input_type":"DropdownInput"},"sender_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"AI","name":"sender_name","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Name of the sender.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"session_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"session_id","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"should_store_message":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"should_store_message","display_name":"Store Messages","advanced":true,"dynamic":false,"info":"Store the message in the history.","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message"],"display_name":"Chat Output","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"message","display_name":"Message","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","should_store_message","sender","sender_name","session_id","data_template"],"beta":false,"edited":false,"lf_version":"1.0.14"},"id":"ChatOutput-C4hM5"},"selected":false,"width":384,"height":294,"positionAbsolute":{"x":1542.131014501705,"y":-399.3944410479402},"dragging":false},{"id":"Prompt-xqk1g","type":"genericNode","position":{"x":620.7903718357475,"y":-622.1759713343845},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":"You are a heplful agent.\n\nYou can search and scrape pages. \n\nBe mindful about the user request and if needed research one more time before providing a final instruction to the user. \n\nFeel free to do more researches after scraping a page, also you can access nested pages to provide detailed instrutions to the user","name":"template","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt","_input_type":"PromptInput"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":[]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false,"lf_version":"1.0.14"},"id":"Prompt-xqk1g"},"selected":false,"width":384,"height":322,"positionAbsolute":{"x":620.7903718357475,"y":-622.1759713343845},"dragging":false},{"id":"OpenAIModel-QiueJ","type":"genericNode","position":{"x":648.4328507489071,"y":-246.0440760881861},"data":{"type":"OpenAIModel","node":{"template":{"_type":"Component","api_key":{"load_from_db":true,"required":false,"placeholder":"","show":true,"value":"","name":"api_key","display_name":"OpenAI API Key","advanced":false,"input_types":[],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageInput"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"json_mode","display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool","_input_type":"BoolInput"},"max_tokens":{"trace_as_metadata":true,"range_spec":{"step_type":"float","min":0,"max":128000,"step":0.1},"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int","_input_type":"IntInput"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":{},"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict","_input_type":"DictInput"},"model_name":{"trace_as_metadata":true,"options":["gpt-4o-mini","gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"combobox":false,"required":false,"placeholder":"","show":true,"value":"gpt-4o","name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"DropdownInput"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str","_input_type":"StrInput"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"value":{},"name":"output_schema","display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.","title_case":false,"type":"dict","_input_type":"DictInput"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":1,"name":"seed","display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int","_input_type":"IntInput"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool","_input_type":"BoolInput"},"system_message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"system_message","display_name":"System Message","advanced":true,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":0.1,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","api_key","temperature","seed"],"beta":false,"edited":false,"lf_version":"1.0.14"},"id":"OpenAIModel-QiueJ"},"selected":false,"width":384,"height":466,"positionAbsolute":{"x":648.4328507489071,"y":-246.0440760881861},"dragging":false},{"id":"SearchAPI-EMi5V","type":"genericNode","position":{"x":190.93856144379936,"y":-783.49474766163},"data":{"type":"SearchAPI","node":{"template":{"_type":"Component","api_key":{"load_from_db":true,"required":true,"placeholder":"","show":true,"value":"","name":"api_key","display_name":"SearchAPI API Key","advanced":false,"input_types":[],"dynamic":false,"info":"","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Union, Optional\r\nfrom langchain_community.utilities.searchapi import SearchApiAPIWrapper\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.inputs import SecretStrInput, MultilineInput, DictInput, MessageTextInput\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\nfrom pydantic import BaseModel, Field\r\n\r\nclass SearchAPIComponent(LCToolComponent):\r\n    display_name: str = \"Search API\"\r\n    description: str = \"Call the searchapi.io API\"\r\n    name = \"SearchAPI\"\r\n    documentation: str = \"https://www.searchapi.io/docs/google\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"engine\", display_name=\"Engine\", value=\"google\"),\r\n        SecretStrInput(name=\"api_key\", display_name=\"SearchAPI API Key\", required=True),\r\n        MultilineInput(\r\n            name=\"input_value\",\r\n            display_name=\"Input\",\r\n        ),\r\n        DictInput(name=\"search_params\", display_name=\"Search parameters\", advanced=True, is_list=True),\r\n    ]\r\n\r\n    class SearchAPISchema(BaseModel):\r\n        query: str = Field(..., description=\"The search query\")\r\n        search_params: Optional[dict] = Field(default=None, description=\"Additional search parameters\")\r\n\r\n    def run_model(self) -> Union[Data, list[Data]]:\r\n        wrapper = self._build_wrapper()\r\n        results = wrapper.results(query=self.input_value, **(self.search_params or {}))\r\n        list_results = results.get(\"organic_results\", [])\r\n        data = [Data(data=result, text=result[\"snippet\"]) for result in list_results]\r\n        self.status = data\r\n        return data\r\n\r\n    def build_tool(self) -> Tool:\r\n        return StructuredTool.from_function(\r\n            name=\"search_api\",\r\n            description=\"Search for recent results using searchapi.io. Input should be a search query string.\",\r\n            func=self._search,\r\n            args_schema=self.SearchAPISchema,\r\n        )\r\n\r\n    def _build_wrapper(self):\r\n        return SearchApiAPIWrapper(engine=self.engine, searchapi_api_key=self.api_key)\r\n\r\n    def _search(self, query: str, search_params: Optional[dict] = None) -> list[dict]:\r\n        wrapper = self._build_wrapper()\r\n        results = wrapper.results(query=query, **(search_params or {}))\r\n        return results.get(\"organic_results\", [])","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"engine":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"google","name":"engine","display_name":"Engine","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"input_value":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"langflow docs","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MultilineInput"},"search_params":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"value":{},"name":"search_params","display_name":"Search parameters","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict","_input_type":"DictInput"}},"description":"Call the searchapi.io API","base_classes":["Data","list","Tool"],"display_name":"Search API","documentation":"https://www.searchapi.io/docs/google","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data","list"],"selected":"Data","name":"api_run_model","display_name":"Data","method":"run_model","value":"__UNDEFINED__","cache":true},{"types":["Tool"],"selected":"Tool","name":"api_build_tool","display_name":"Tool","method":"build_tool","value":"__UNDEFINED__","cache":true}],"field_order":["engine","api_key","input_value","search_params"],"beta":false,"edited":true,"official":false,"lf_version":"1.0.14"},"id":"SearchAPI-EMi5V"},"selected":false,"width":384,"height":507,"positionAbsolute":{"x":190.93856144379936,"y":-783.49474766163},"dragging":false},{"id":"FirecrawlScrapeApi-f2b0h","type":"genericNode","position":{"x":186.2601187554925,"y":-253.72051781043973},"data":{"type":"firecrawl_scrape_api","node":{"template":{"_type":"Component","api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"api_key","display_name":"API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The API key to use Firecrawl API.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.inputs import MessageTextInput, IntInput, DictInput, SecretStrInput\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\nfrom pydantic import BaseModel, Field\r\n\r\nclass FirecrawlScrapeApiComponent(LCToolComponent):\r\n    display_name: str = \"Firecrawl Scrape API\"\r\n    description: str = \"Scrape web content using Firecrawl API.\"\r\n    name = \"firecrawl_scrape_api\"\r\n    documentation: str = \"https://docs.firecrawl.dev/api-reference/endpoint/scrape\"\r\n    icon = \"FirecrawlCrawlApi\"\r\n\r\n    inputs = [\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"API Key\",\r\n            info=\"The API key to use Firecrawl API.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"url\",\r\n            display_name=\"URL\",\r\n            info=\"The URL to scrape.\",\r\n        ),\r\n        IntInput(\r\n            name=\"timeout\",\r\n            display_name=\"Timeout\",\r\n            info=\"Timeout in milliseconds for the request.\",\r\n            value=10000,\r\n        ),\r\n        DictInput(\r\n            name=\"pageOptions\",\r\n            display_name=\"Page Options\",\r\n            info=\"The page options to send with the request.\",\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"extractorOptions\",\r\n            display_name=\"Extractor Options\",\r\n            info=\"The extractor options to send with the request.\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    class FirecrawlScrapeApiSchema(BaseModel):\r\n        url: str = Field(..., description=\"The URL to scrape\")\r\n        timeout: int = Field(default=10000, description=\"Timeout in milliseconds for the request\")\r\n        pageOptions: Optional[dict] = Field(default=None, description=\"The page options to send with the request\")\r\n        extractorOptions: Optional[dict] = Field(default=None, description=\"The extractor options to send with the request\")\r\n\r\n    def run_model(self) -> Data:\r\n        try:\r\n            from firecrawl.firecrawl import FirecrawlApp\r\n        except ImportError:\r\n            raise ImportError(\r\n                \"Could not import firecrawl integration package. \"\r\n                \"Please install it with `pip install firecrawl-py`.\"\r\n            )\r\n\r\n        app = FirecrawlApp(api_key=self.api_key)\r\n        results = app.scrape_url(\r\n            self.url,\r\n            {\r\n                \"timeout\": str(self.timeout),\r\n                \"extractorOptions\": self.extractorOptions or {},\r\n                \"pageOptions\": self.pageOptions or {},\r\n            },\r\n        )\r\n\r\n        data = Data(data=results)\r\n        self.status = data\r\n        return data\r\n\r\n    def build_tool(self) -> Tool:\r\n        return StructuredTool.from_function(\r\n            name=\"firecrawl_scrape_api\",\r\n            description=\"Scrape web content using Firecrawl API. Input should be a dictionary with 'url' and optional 'timeout', 'pageOptions', and 'extractorOptions'.\",\r\n            func=self._scrape_url,\r\n            args_schema=self.FirecrawlScrapeApiSchema,\r\n        )\r\n\r\n    def _scrape_url(self, url: str, timeout: int = 10000, pageOptions: Optional[dict] = None, extractorOptions: Optional[dict] = None) -> dict:\r\n        try:\r\n            from firecrawl.firecrawl import FirecrawlApp\r\n        except ImportError:\r\n            raise ImportError(\r\n                \"Could not import firecrawl integration package. \"\r\n                \"Please install it with `pip install firecrawl-py`.\"\r\n            )\r\n\r\n        app = FirecrawlApp(api_key=self.api_key)\r\n        results = app.scrape_url(\r\n            url,\r\n            {\r\n                \"timeout\": str(timeout),\r\n                \"extractorOptions\": extractorOptions or {},\r\n                \"pageOptions\": pageOptions or {},\r\n            },\r\n        )\r\n\r\n        return results","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"extractorOptions":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":{},"name":"extractorOptions","display_name":"Extractor Options","advanced":true,"dynamic":false,"info":"The extractor options to send with the request.","title_case":false,"type":"dict","_input_type":"DictInput"},"pageOptions":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":{},"name":"pageOptions","display_name":"Page Options","advanced":true,"dynamic":false,"info":"The page options to send with the request.","title_case":false,"type":"dict","_input_type":"DictInput"},"timeout":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":10000,"name":"timeout","display_name":"Timeout","advanced":false,"dynamic":false,"info":"Timeout in milliseconds for the request.","title_case":false,"type":"int","_input_type":"IntInput"},"url":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"https://docs.langflow.org","name":"url","display_name":"URL","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The URL to scrape.","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Scrape web content using Firecrawl API.","icon":"FirecrawlCrawlApi","base_classes":["Data","list","Tool"],"display_name":"FirecrawlScrape Tool","documentation":"https://docs.firecrawl.dev/api-reference/endpoint/scrape","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data","list"],"selected":"Data","name":"api_run_model","display_name":"Data","method":"run_model","value":"__UNDEFINED__","cache":true},{"types":["Tool"],"selected":"Tool","name":"api_build_tool","display_name":"Tool","method":"build_tool","value":"__UNDEFINED__","cache":true}],"field_order":["api_key","url","timeout","pageOptions","extractorOptions"],"beta":false,"edited":true,"lf_version":"1.0.14"},"id":"FirecrawlScrapeApi-f2b0h"},"selected":true,"width":384,"height":503,"positionAbsolute":{"x":186.2601187554925,"y":-253.72051781043973},"dragging":false},{"id":"LangWatchEvaluatorComponent-1pA7M","type":"genericNode","position":{"x":2005.5733175731548,"y":-648.5994701548258},"data":{"type":"LangWatchEvaluatorComponent","node":{"template":{"_type":"Component","answer":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"answer","display_name":"Chat Output","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The generated answer to be evaluated.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import re\r\nfrom langflow.custom import Component\r\nfrom langflow.inputs import MessageTextInput, DataInput\r\nfrom langflow.schema.message import Message\r\nfrom langflow.template import Output\r\nfrom langflow.schema import Data\r\nimport langwatch\r\nimport os\r\n\r\nclass LangWatchEvaluatorComponent(Component):\r\n    display_name = \"LangWatch Evaluator\"\r\n    description = \"Evaluates a question-answer pair using LangWatch and provides a trace URL.\"\r\n    icon = \"view\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"question\",\r\n            display_name=\"Chat Input\",\r\n            info=\"The question to be evaluated.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"answer\",\r\n            display_name=\"Chat Output\",\r\n            info=\"The generated answer to be evaluated.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"ground_truth\",\r\n            display_name=\"Resposta Correta\",\r\n            info=\"The expected correct answer.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_email\",\r\n            display_name=\"User Email\",\r\n            info=\"The user ID for the trace metadata.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_name\",\r\n            display_name=\"Participant Name\",\r\n            info=\"Full name for identification in the trace metadata.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_cpf\",\r\n            display_name=\"Participant CPF\",\r\n            info=\"CPF for identification in for the trace metadata.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"question_id\",\r\n            display_name=\"Question ID\",\r\n            info=\"The question ID for the trace metadata.\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Trace\", name=\"trace_url\", method=\"evaluate\"),\r\n    ]\r\n\r\n    async def evaluate(self) -> Data:\r\n        question = self.question\r\n        answer = self.answer\r\n        ground_truth = self.ground_truth\r\n        user_email = self.user_email if self.user_email else \"\"\r\n        question_id = self.question_id if self.question_id else \"\"\r\n        user_name = self.user_name if self.user_name else \"\"\r\n        user_cpf = self.user_cpf if self.user_cpf else \"\"\r\n\r\n        # Validate email if provided\r\n        if user_email and not self.validate_email(user_email):\r\n            raise ValueError(f\"Invalid email address: {user_email}\")\r\n\r\n        # Validate CPF if provided\r\n        if user_cpf and not self.validate_cpf(user_cpf):\r\n            raise ValueError(f\"Invalid CPF: {user_cpf}\")\r\n        \r\n        flow_trace_id =  \"\"\r\n        if hasattr(self, 'tracing_service'):\r\n            langwatch_tracer = self.tracing_service._tracers['langwatch']\r\n            if langwatch_tracer:\r\n                current_trace = langwatch_tracer.trace\r\n                trace_id = current_trace.trace_id if current_trace else None\r\n                logger.debug(f\"LANGWATCH FLOW TRACE ID: {trace_id}\")\r\n                flow_trace_id = trace_id\r\n                \r\n        langwatch.api_key = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0aW1lc3RhbXAiOjE3MjExNTE2NTY3MDQsInJhbmQiOjAuNjgzNzI5NDExMTcyMzYsImlhdCI6MTcyMTE1MTY1Nn0.IHNSVO1N2uaUjl5y2j_E0AwvuvFOwo5y56dpNg4QNBo'\r\n\r\n        trace = langwatch.trace(\r\n            metadata={\r\n                \"user_id\": user_email,\r\n                \"question_id\": question_id,\r\n                \"user_name\": user_name,\r\n                \"user_cpf\": user_cpf\r\n            },\r\n            expected_output=ground_truth\r\n        )\r\n        \r\n        rag_span = trace.span(type=\"rag\", name=\"LangWatch Evaluator\", input=question, output=answer)\r\n        rag_span.end()\r\n\r\n        trace.send_spans()\r\n\r\n        public_url = trace.share()\r\n        \r\n        langwatch_data = Data(flow_trace_id=flow_trace_id, eval_url=public_url)\r\n        self.status = langwatch_data\r\n        return langwatch_data\r\n        \r\n    def validate_email(self, email):\r\n        pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\r\n        return re.match(pattern, email) is not None\r\n\r\n    def validate_cpf(self, cpf):\r\n        if not re.match(r'^(?!(\\d)\\1{10})\\d{9}[\\d]{2}$', cpf):\r\n            return False\r\n\r\n        total = sum(int(cpf[i]) * (10 - i) for i in range(9))\r\n        check1 = (total * 10 % 11) % 10\r\n\r\n        total = sum(int(cpf[i]) * (11 - i) for i in range(10))\r\n        check2 = (total * 10 % 11) % 10\r\n\r\n        return cpf[-2:] == f\"{check1}{check2}\"","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"ground_truth":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"Agent","name":"ground_truth","display_name":"Resposta Correta","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The expected correct answer.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"question":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"question","display_name":"Chat Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The question to be evaluated.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"question_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"question_id","display_name":"Question ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The question ID for the trace metadata.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"user_cpf":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"user_cpf","display_name":"Participant CPF","advanced":true,"input_types":["Message"],"dynamic":false,"info":"CPF for identification in for the trace metadata.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"user_email":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"user_email","display_name":"User Email","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The user ID for the trace metadata.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"user_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"user_name","display_name":"Participant Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Full name for identification in the trace metadata.","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Evaluates a question-answer pair using LangWatch and provides a trace URL.","icon":"view","base_classes":["Data"],"display_name":"Langwatch Evaluator - Agent","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"trace_url","display_name":"Trace","method":"evaluate","value":"__UNDEFINED__","cache":true}],"field_order":["question","answer","ground_truth","user_email","user_name","user_cpf","question_id"],"beta":false,"edited":true,"lf_version":"1.0.14"},"id":"LangWatchEvaluatorComponent-1pA7M"},"selected":false,"width":384,"height":494,"positionAbsolute":{"x":2005.5733175731548,"y":-648.5994701548258},"dragging":false}],"edges":[{"source":"Prompt-xqk1g","sourceHandle":"{dataType:Prompt,id:Prompt-xqk1g,name:prompt,output_types:[Message]}","target":"ToolCallingAgent-G6W7l","targetHandle":"{fieldName:system_prompt,id:ToolCallingAgent-G6W7l,inputTypes:[Message],type:str}","data":{"targetHandle":{"fieldName":"system_prompt","id":"ToolCallingAgent-G6W7l","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-xqk1g","name":"prompt","output_types":["Message"]}},"id":"reactflow__edge-Prompt-xqk1g{dataType:Prompt,id:Prompt-xqk1g,name:prompt,output_types:[Message]}-ToolCallingAgent-G6W7l{fieldName:system_prompt,id:ToolCallingAgent-G6W7l,inputTypes:[Message],type:str}","className":""},{"source":"OpenAIModel-QiueJ","sourceHandle":"{dataType:OpenAIModel,id:OpenAIModel-QiueJ,name:model_output,output_types:[LanguageModel]}","target":"ToolCallingAgent-G6W7l","targetHandle":"{fieldName:llm,id:ToolCallingAgent-G6W7l,inputTypes:[LanguageModel],type:other}","data":{"targetHandle":{"fieldName":"llm","id":"ToolCallingAgent-G6W7l","inputTypes":["LanguageModel"],"type":"other"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-QiueJ","name":"model_output","output_types":["LanguageModel"]}},"id":"reactflow__edge-OpenAIModel-QiueJ{dataType:OpenAIModel,id:OpenAIModel-QiueJ,name:model_output,output_types:[LanguageModel]}-ToolCallingAgent-G6W7l{fieldName:llm,id:ToolCallingAgent-G6W7l,inputTypes:[LanguageModel],type:other}","className":""},{"source":"ChatInput-zVfXN","sourceHandle":"{dataType:ChatInput,id:ChatInput-zVfXN,name:message,output_types:[Message]}","target":"ToolCallingAgent-G6W7l","targetHandle":"{fieldName:input_value,id:ToolCallingAgent-G6W7l,inputTypes:[Message],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"ToolCallingAgent-G6W7l","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ChatInput","id":"ChatInput-zVfXN","name":"message","output_types":["Message"]}},"id":"reactflow__edge-ChatInput-zVfXN{dataType:ChatInput,id:ChatInput-zVfXN,name:message,output_types:[Message]}-ToolCallingAgent-G6W7l{fieldName:input_value,id:ToolCallingAgent-G6W7l,inputTypes:[Message],type:str}","selected":false,"className":""},{"source":"FirecrawlScrapeApi-f2b0h","sourceHandle":"{dataType:firecrawl_scrape_api,id:FirecrawlScrapeApi-f2b0h,name:api_build_tool,output_types:[Tool]}","target":"ToolCallingAgent-G6W7l","targetHandle":"{fieldName:tools,id:ToolCallingAgent-G6W7l,inputTypes:[Tool,BaseTool],type:other}","data":{"targetHandle":{"fieldName":"tools","id":"ToolCallingAgent-G6W7l","inputTypes":["Tool","BaseTool"],"type":"other"},"sourceHandle":{"dataType":"firecrawl_scrape_api","id":"FirecrawlScrapeApi-f2b0h","name":"api_build_tool","output_types":["Tool"]}},"className":"","id":"reactflow__edge-FirecrawlScrapeApi-f2b0h{dataType:firecrawl_scrape_api,id:FirecrawlScrapeApi-f2b0h,name:api_build_tool,output_types:[Tool]}-ToolCallingAgent-G6W7l{fieldName:tools,id:ToolCallingAgent-G6W7l,inputTypes:[Tool,BaseTool],type:other}"},{"source":"ToolCallingAgent-G6W7l","sourceHandle":"{dataType:ToolCallingAgent,id:ToolCallingAgent-G6W7l,name:response,output_types:[Message]}","target":"ChatOutput-C4hM5","targetHandle":"{fieldName:input_value,id:ChatOutput-C4hM5,inputTypes:[Message],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-C4hM5","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ToolCallingAgent","id":"ToolCallingAgent-G6W7l","name":"response","output_types":["Message"]}},"id":"reactflow__edge-ToolCallingAgent-G6W7l{dataType:ToolCallingAgent,id:ToolCallingAgent-G6W7l,name:response,output_types:[Message]}-ChatOutput-C4hM5{fieldName:input_value,id:ChatOutput-C4hM5,inputTypes:[Message],type:str}","className":""},{"source":"ChatOutput-C4hM5","sourceHandle":"{dataType:ChatOutput,id:ChatOutput-C4hM5,name:message,output_types:[Message]}","target":"LangWatchEvaluatorComponent-1pA7M","targetHandle":"{fieldName:answer,id:LangWatchEvaluatorComponent-1pA7M,inputTypes:[Message],type:str}","data":{"targetHandle":{"fieldName":"answer","id":"LangWatchEvaluatorComponent-1pA7M","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ChatOutput","id":"ChatOutput-C4hM5","name":"message","output_types":["Message"]}},"id":"reactflow__edge-ChatOutput-C4hM5{dataType:ChatOutput,id:ChatOutput-C4hM5,name:message,output_types:[Message]}-LangWatchEvaluatorComponent-1pA7M{fieldName:answer,id:LangWatchEvaluatorComponent-1pA7M,inputTypes:[Message],type:str}","className":""},{"source":"ChatInput-zVfXN","sourceHandle":"{dataType:ChatInput,id:ChatInput-zVfXN,name:message,output_types:[Message]}","target":"LangWatchEvaluatorComponent-1pA7M","targetHandle":"{fieldName:question,id:LangWatchEvaluatorComponent-1pA7M,inputTypes:[Message],type:str}","data":{"targetHandle":{"fieldName":"question","id":"LangWatchEvaluatorComponent-1pA7M","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ChatInput","id":"ChatInput-zVfXN","name":"message","output_types":["Message"]}},"id":"reactflow__edge-ChatInput-zVfXN{dataType:ChatInput,id:ChatInput-zVfXN,name:message,output_types:[Message]}-LangWatchEvaluatorComponent-1pA7M{fieldName:question,id:LangWatchEvaluatorComponent-1pA7M,inputTypes:[Message],type:str}","className":""},{"source":"SearchAPI-EMi5V","sourceHandle":"{dataType:SearchAPI,id:SearchAPI-EMi5V,name:api_build_tool,output_types:[Tool]}","target":"ToolCallingAgent-G6W7l","targetHandle":"{fieldName:tools,id:ToolCallingAgent-G6W7l,inputTypes:[Tool,BaseTool],type:other}","data":{"targetHandle":{"fieldName":"tools","id":"ToolCallingAgent-G6W7l","inputTypes":["Tool","BaseTool"],"type":"other"},"sourceHandle":{"dataType":"SearchAPI","id":"SearchAPI-EMi5V","name":"api_build_tool","output_types":["Tool"]}},"id":"reactflow__edge-SearchAPI-EMi5V{dataType:SearchAPI,id:SearchAPI-EMi5V,name:api_build_tool,output_types:[Tool]}-ToolCallingAgent-G6W7l{fieldName:tools,id:ToolCallingAgent-G6W7l,inputTypes:[Tool,BaseTool],type:other}","className":""}],"viewport":{"x":214.35332294088704,"y":654.1758891461404,"zoom":0.7578582832552012}},"description":"Crafting Conversations, One Node at a Time.","name":"Agent - Basic Langflow - Live","last_tested_version":"1.0.14","endpoint_name":null,"is_component":false}