{"id":"29593f9b-11d6-4568-83b3-e84478a403f7","data":{"nodes":[{"id":"Prompt-pJTkT","type":"genericNode","position":{"x":6083.458822194794,"y":450.4374932147307},"data":{"description":"Create a prompt template with dynamic variables.","display_name":"Prompt","id":"Prompt-pJTkT","node":{"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n"},"context":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"context","display_name":"context","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"template":{"advanced":false,"display_name":"Template","dynamic":false,"info":"","list":false,"load_from_db":false,"name":"template","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_input":true,"type":"prompt","value":"{context}\n\n---\n\nBaseado no context e na resposta, crie um resultado no formato 'csv' da seguinte forma:\nApenas para o preencimento da resposta use a variÃ¡vel 'resposta'\nResultado dos scores de:\nAnswer Correctness Score; Ragas Faithfulness Score; Ragas  Ragas Context Precision Score; Ragas Context Recall Score; input, generated\n\n\nresultado:"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["context"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"type":"Prompt"},"selected":false,"width":384,"height":423,"positionAbsolute":{"x":6083.458822194794,"y":450.4374932147307},"dragging":true},{"id":"OpenAIModel-WG3Dc","type":"genericNode","position":{"x":6573.616859476539,"y":635.2110741179064},"data":{"type":"OpenAIModel","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"json_mode","display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool"},"max_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":{},"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict"},"model_name":{"trace_as_metadata":true,"options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"required":false,"placeholder":"","show":true,"value":"gpt-3.5-turbo","name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str"},"openai_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"input_types":[],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"value":{},"name":"output_schema","display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.","title_case":false,"type":"dict"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":1,"name":"seed","display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool"},"system_message":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":0.1,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","openai_api_key","temperature","stream","system_message","seed"],"beta":false,"edited":false},"id":"OpenAIModel-WG3Dc"},"selected":false,"width":384,"height":623},{"id":"FilterData-gSFhS","type":"genericNode","position":{"x":5496.260093635561,"y":438.97170658600453},"data":{"type":"FilterData","node":{"template":{"_type":"Component","data":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"data","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"Data object to filter.","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DataInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\n\r\nclass FilterDataComponent(Component):\r\n    display_name = \"Filter Data\"\r\n    description = \"Filters a Data object based on a list of keys.\"\r\n    icon = \"filter\"\r\n    beta = True\r\n    name = \"FilterData\"\r\n\r\n    inputs = [\r\n        DataInput(\r\n            name=\"data\",\r\n            display_name=\"Data\",\r\n            info=\"Data object to filter.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"filter_criteria\",\r\n            display_name=\"Filter Criteria\",\r\n            info=\"List of keys to filter by.\",\r\n            is_list=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\r\n        Output(display_name=\"Filtered Data (Text)\", name=\"filtered_data_text\", method=\"filter_data_text\"),\r\n    ]\r\n\r\n    def filter_data(self) -> Data:\r\n        filter_criteria: List[str] = self.filter_criteria\r\n        data = self.data.data if isinstance(self.data, Data) else {}\r\n\r\n        # Filter the data\r\n        filtered = {key: value for key, value in data.items() if key in filter_criteria}\r\n\r\n        # Create a new Data object with the filtered data\r\n        filtered_data = Data(data=filtered)\r\n        self.status = filtered_data\r\n        return filtered_data\r\n\r\n    def filter_data_text(self) -> str:\r\n        filter_criteria: List[str] = self.filter_criteria\r\n        data = self.data.data if isinstance(self.data, Data) else {}\r\n\r\n        # Filter the data\r\n        filtered = {key: value for key, value in data.items() if key in filter_criteria}\r\n\r\n        # Convert filtered data to string\r\n        filtered_data_str = \"\\n\".join(f\"{key}: {value}\" for key, value in filtered.items())\r\n\r\n        return filtered_data_str\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"filter_criteria":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":true,"required":false,"placeholder":"","show":true,"value":["content"],"name":"filter_criteria","display_name":"Filter Criteria","advanced":false,"input_types":["Message"],"dynamic":false,"info":"List of keys to filter by.","title_case":false,"type":"str"}},"description":"Filters a Data object based on a list of keys.","icon":"filter","base_classes":["Data","Text"],"display_name":"Filter Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"filtered_data","display_name":"Filtered Data","method":"filter_data","value":"__UNDEFINED__","cache":true},{"types":["Text"],"selected":"Text","name":"filtered_data_text","display_name":"Filtered Data (Text)","method":"filter_data_text","value":"__UNDEFINED__","cache":true}],"field_order":["data","filter_criteria"],"beta":true,"edited":true},"id":"FilterData-gSFhS","description":"Filters a Data object based on a list of keys.","display_name":"Filter Data"},"selected":false,"width":384,"height":405},{"id":"StoreMessage-euB6g","type":"genericNode","position":{"x":5686.885763121141,"y":998.4619002327072},"data":{"type":"StoreMessage","node":{"template":{"_type":"Component","memory":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"memory","display_name":"External Memory","advanced":false,"input_types":["BaseChatMessageHistory"],"dynamic":false,"info":"The external memory to store the message. If empty, it will use the Langflow tables.","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.inputs import MessageInput, StrInput, HandleInput\nfrom langflow.schema.message import Message\nfrom langflow.template import Output\nfrom langflow.memory import get_messages, store_message\n\n\nclass StoreMessageComponent(Component):\n    display_name = \"Store Message\"\n    description = \"Stores a chat message or text into Langflow tables or an external memory.\"\n    icon = \"save\"\n    name = \"StoreMessage\"\n\n    inputs = [\n        MessageInput(name=\"message\", display_name=\"Message\", info=\"The chat message to be stored.\", required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"The external memory to store the message. If empty, it will use the Langflow tables.\",\n        ),\n        StrInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message.\",\n            value=\"AI\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"The name of the sender.\", value=\"AI\", advanced=True\n        ),\n        StrInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat.\",\n            value=\"\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Stored Messages\", name=\"stored_messages\", method=\"store_message\"),\n    ]\n\n    def store_message(self) -> Message:\n        message = self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender\n        message.sender_name = self.sender_name or message.sender_name\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            self.memory.add_messages([lc_message])\n            stored = self.memory.messages\n            stored = [Message.from_lc_message(m) for m in stored]\n            if message.sender:\n                stored = [m for m in stored if m.sender == message.sender]\n        else:\n            store_message(message, flow_id=self.graph.flow_id)\n            stored = get_messages(session_id=message.session_id, sender_name=message.sender_name, sender=message.sender)\n        self.status = stored\n        return stored\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"value":"","name":"message","display_name":"Message","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The chat message to be stored.","title_case":false,"type":"str"},"sender":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"Rank","name":"sender","display_name":"Sender","advanced":true,"dynamic":false,"info":"The sender of the message.","title_case":false,"type":"str"},"sender_name":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"Julio","name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"The name of the sender.","title_case":false,"type":"str"},"session_id":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"teste2","name":"session_id","display_name":"Session ID","advanced":false,"dynamic":false,"info":"The session ID of the chat.","title_case":false,"type":"str"}},"description":"Stores a chat message or text into Langflow tables or an external memory.","icon":"save","base_classes":["Message"],"display_name":"Store Message","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"stored_messages","display_name":"Stored Messages","method":"store_message","value":"__UNDEFINED__","cache":true}],"field_order":["message","memory","sender","sender_name","session_id"],"beta":false,"edited":false},"id":"StoreMessage-euB6g"},"selected":false,"width":384,"height":471},{"id":"SaveToCSV-UC55G","type":"genericNode","position":{"x":4848.050213522178,"y":1165.7452996463173},"data":{"type":"SaveToCSV","node":{"template":{"_type":"Component","stored_messages":{"trace_as_metadata":true,"list":false,"required":true,"placeholder":"","show":true,"value":"","name":"stored_messages","display_name":"Stored Messages","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The stored messages to be saved in CSV format.","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import csv\r\nfrom typing import List\r\nfrom langflow.custom import Component\r\nfrom langflow.inputs import StrInput, HandleInput\r\nfrom langflow.schema.message import Message\r\nfrom langflow.template import Output\r\nfrom langflow.memory import get_messages\r\n\r\nclass SaveToCSVComponent(Component):\r\n    display_name = \"Save to CSV\"\r\n    description = \"Saves stored messages to a CSV file.\"\r\n    icon = \"save\"\r\n    name = \"SaveToCSV\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"stored_messages\",\r\n            display_name=\"Stored Messages\",\r\n            input_types=[\"Message\"],\r\n            info=\"The stored messages to be saved in CSV format.\",\r\n            required=True\r\n        ),\r\n        StrInput(name=\"filename\", display_name=\"Filename\", info=\"The name of the CSV file.\", value=\"output.csv\", required=True),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"File Path\", name=\"file_path\", method=\"save_to_csv\"),\r\n    ]\r\n\r\n    def save_to_csv(self) -> str:\r\n        stored_messages: List[Message] = self.stored_messages\r\n        filename: str = self.filename\r\n\r\n        # Convert messages to a list of dictionaries\r\n        messages_data = [\r\n            {\r\n                \"session_id\": message.session_id,\r\n                \"text\": message.text,\r\n                \"timestamp\": message.timestamp,\r\n            }\r\n            for message in stored_messages\r\n        ]\r\n\r\n        # Define the fieldnames for the CSV file\r\n        fieldnames = [\"session_id\", \"text\", \"timestamp\"]\r\n\r\n        # Write the data to a CSV file\r\n        with open(filename, mode='w', newline='') as file:\r\n            writer = csv.DictWriter(file, fieldnames=fieldnames)\r\n            writer.writeheader()\r\n            for row in messages_data:\r\n                writer.writerow(row)\r\n\r\n        # Return the file path\r\n        self.status = filename\r\n        return filename\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"filename":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"value":"results/output.csv","name":"filename","display_name":"Filename","advanced":false,"dynamic":false,"info":"The name of the CSV file.","title_case":false,"type":"str"}},"description":"Saves stored messages to a CSV file.","icon":"save","base_classes":["Text"],"display_name":"Custom Component","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Text"],"selected":"Text","name":"file_path","display_name":"File Path","method":"save_to_csv","value":"__UNDEFINED__","cache":true}],"field_order":["stored_messages","filename"],"beta":false,"edited":true},"id":"SaveToCSV-UC55G","description":"Saves stored messages to a CSV file.","display_name":"Custom Component"},"selected":false,"width":384,"height":349,"positionAbsolute":{"x":4848.050213522178,"y":1165.7452996463173},"dragging":false},{"id":"FirecrawlScrapeApi-sFYt9","type":"genericNode","position":{"x":4843.129952787913,"y":350.85121060672395},"data":{"type":"FirecrawlScrapeApi","node":{"template":{"_type":"CustomComponent","extractorOptions":{"type":"Data","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"extractorOptions","display_name":"Extractor Options","advanced":false,"dynamic":false,"info":"The extractor options to send with the request.","load_from_db":false,"title_case":false},"pageOptions":{"type":"Data","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"pageOptions","display_name":"Page Options","advanced":false,"dynamic":false,"info":"The page options to send with the request.","load_from_db":false,"title_case":false},"api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"api_key","display_name":"API Key","advanced":false,"dynamic":false,"info":"The API key to use Firecrawl API.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Data\n\n\nclass FirecrawlScrapeApi(CustomComponent):\n    display_name: str = \"FirecrawlScrapeApi\"\n    description: str = \"Firecrawl Scrape API.\"\n    name = \"FirecrawlScrapeApi\"\n\n    output_types: list[str] = [\"Document\"]\n    documentation: str = \"https://docs.firecrawl.dev/api-reference/endpoint/scrape\"\n    field_config = {\n        \"api_key\": {\n            \"display_name\": \"API Key\",\n            \"field_type\": \"str\",\n            \"required\": True,\n            \"password\": True,\n            \"info\": \"The API key to use Firecrawl API.\",\n        },\n        \"url\": {\n            \"display_name\": \"URL\",\n            \"field_type\": \"str\",\n            \"required\": True,\n            \"info\": \"The URL to scrape.\",\n        },\n        \"timeout\": {\n            \"display_name\": \"Timeout\",\n            \"info\": \"Timeout in milliseconds for the request.\",\n            \"field_type\": \"int\",\n            \"default_value\": 10000,\n        },\n        \"pageOptions\": {\n            \"display_name\": \"Page Options\",\n            \"info\": \"The page options to send with the request.\",\n        },\n        \"extractorOptions\": {\n            \"display_name\": \"Extractor Options\",\n            \"info\": \"The extractor options to send with the request.\",\n        },\n    }\n\n    def build(\n        self,\n        api_key: str,\n        url: str,\n        timeout: int = 10000,\n        pageOptions: Optional[Data] = None,\n        extractorOptions: Optional[Data] = None,\n    ) -> Data:\n        try:\n            from firecrawl.firecrawl import FirecrawlApp  # type: ignore\n        except ImportError:\n            raise ImportError(\n                \"Could not import firecrawl integration package. \" \"Please install it with `pip install firecrawl-py`.\"\n            )\n        if extractorOptions:\n            extractor_options_dict = extractorOptions.__dict__[\"data\"][\"text\"]\n        else:\n            extractor_options_dict = {}\n\n        if pageOptions:\n            page_options_dict = pageOptions.__dict__[\"data\"][\"text\"]\n        else:\n            page_options_dict = {}\n\n        app = FirecrawlApp(api_key=api_key)\n        results = app.scrape_url(\n            url,\n            {\n                \"timeout\": str(timeout),\n                \"extractorOptions\": extractor_options_dict,\n                \"pageOptions\": page_options_dict,\n            },\n        )\n\n        record = Data(data=results)\n        return record\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"timeout":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"40000","fileTypes":[],"file_path":"","password":false,"name":"timeout","display_name":"Timeout","advanced":false,"dynamic":false,"info":"Timeout in milliseconds for the request.","load_from_db":false,"title_case":false},"url":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"url","display_name":"URL","advanced":false,"dynamic":false,"info":"The URL to scrape.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"https://app.langwatch.ai/share/4y731ZJy08KnzALDAJWyO"}},"description":"Firecrawl Scrape API.","base_classes":["Data"],"display_name":"FirecrawlScrapeApi","documentation":"https://docs.firecrawl.dev/api-reference/endpoint/scrape","custom_fields":{"api_key":null,"url":null,"timeout":null,"pageOptions":null,"extractorOptions":null},"output_types":["Data"],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"data","hidden":null,"display_name":"Data","method":null,"value":"__UNDEFINED__","cache":true}],"field_order":["api_key","url","timeout","pageOptions","extractorOptions"],"beta":false,"edited":false},"id":"FirecrawlScrapeApi-sFYt9"},"selected":true,"width":384,"height":581,"dragging":false}],"edges":[{"source":"Prompt-pJTkT","target":"OpenAIModel-WG3Dc","sourceHandle":"{ÅdataTypeÅ:ÅPromptÅ,ÅidÅ:ÅPrompt-pJTkTÅ,ÅnameÅ:ÅpromptÅ,Åoutput_typesÅ:[ÅMessageÅ]}","targetHandle":"{ÅfieldNameÅ:Åinput_valueÅ,ÅidÅ:ÅOpenAIModel-WG3DcÅ,ÅinputTypesÅ:[ÅMessageÅ],ÅtypeÅ:ÅstrÅ}","id":"reactflow__edge-Prompt-pJTkT{ÅdataTypeÅ:ÅPromptÅ,ÅidÅ:ÅPrompt-pJTkTÅ,ÅnameÅ:ÅpromptÅ,Åoutput_typesÅ:[ÅMessageÅ]}-OpenAIModel-WG3Dc{ÅfieldNameÅ:Åinput_valueÅ,ÅidÅ:ÅOpenAIModel-WG3DcÅ,ÅinputTypesÅ:[ÅMessageÅ],ÅtypeÅ:ÅstrÅ}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-WG3Dc","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-pJTkT","name":"prompt","output_types":["Message"]}},"selected":false,"className":""},{"source":"FilterData-gSFhS","target":"Prompt-pJTkT","sourceHandle":"{ÅdataTypeÅ:ÅFilterDataÅ,ÅidÅ:ÅFilterData-gSFhSÅ,ÅnameÅ:Åfiltered_data_textÅ,Åoutput_typesÅ:[ÅTextÅ]}","targetHandle":"{ÅfieldNameÅ:ÅcontextÅ,ÅidÅ:ÅPrompt-pJTkTÅ,ÅinputTypesÅ:[ÅMessageÅ,ÅTextÅ],ÅtypeÅ:ÅstrÅ}","id":"reactflow__edge-FilterData-gSFhS{ÅdataTypeÅ:ÅFilterDataÅ,ÅidÅ:ÅFilterData-gSFhSÅ,ÅnameÅ:Åfiltered_data_textÅ,Åoutput_typesÅ:[ÅTextÅ]}-Prompt-pJTkT{ÅfieldNameÅ:ÅcontextÅ,ÅidÅ:ÅPrompt-pJTkTÅ,ÅinputTypesÅ:[ÅMessageÅ,ÅTextÅ],ÅtypeÅ:ÅstrÅ}","data":{"targetHandle":{"fieldName":"context","id":"Prompt-pJTkT","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"FilterData","id":"FilterData-gSFhS","name":"filtered_data_text","output_types":["Text"]}},"selected":false,"className":""},{"source":"OpenAIModel-WG3Dc","target":"StoreMessage-euB6g","sourceHandle":"{ÅdataTypeÅ:ÅOpenAIModelÅ,ÅidÅ:ÅOpenAIModel-WG3DcÅ,ÅnameÅ:Åtext_outputÅ,Åoutput_typesÅ:[ÅMessageÅ]}","targetHandle":"{ÅfieldNameÅ:ÅmessageÅ,ÅidÅ:ÅStoreMessage-euB6gÅ,ÅinputTypesÅ:[ÅMessageÅ],ÅtypeÅ:ÅstrÅ}","id":"reactflow__edge-OpenAIModel-WG3Dc{ÅdataTypeÅ:ÅOpenAIModelÅ,ÅidÅ:ÅOpenAIModel-WG3DcÅ,ÅnameÅ:Åtext_outputÅ,Åoutput_typesÅ:[ÅMessageÅ]}-StoreMessage-euB6g{ÅfieldNameÅ:ÅmessageÅ,ÅidÅ:ÅStoreMessage-euB6gÅ,ÅinputTypesÅ:[ÅMessageÅ],ÅtypeÅ:ÅstrÅ}","data":{"targetHandle":{"fieldName":"message","id":"StoreMessage-euB6g","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-WG3Dc","name":"text_output","output_types":["Message"]}},"selected":false,"className":""},{"source":"StoreMessage-euB6g","target":"SaveToCSV-UC55G","sourceHandle":"{ÅdataTypeÅ:ÅStoreMessageÅ,ÅidÅ:ÅStoreMessage-euB6gÅ,ÅnameÅ:Åstored_messagesÅ,Åoutput_typesÅ:[ÅMessageÅ]}","targetHandle":"{ÅfieldNameÅ:Åstored_messagesÅ,ÅidÅ:ÅSaveToCSV-UC55GÅ,ÅinputTypesÅ:[ÅMessageÅ],ÅtypeÅ:ÅotherÅ}","id":"reactflow__edge-StoreMessage-euB6g{ÅdataTypeÅ:ÅStoreMessageÅ,ÅidÅ:ÅStoreMessage-euB6gÅ,ÅnameÅ:Åstored_messagesÅ,Åoutput_typesÅ:[ÅMessageÅ]}-SaveToCSV-UC55G{ÅfieldNameÅ:Åstored_messagesÅ,ÅidÅ:ÅSaveToCSV-UC55GÅ,ÅinputTypesÅ:[ÅMessageÅ],ÅtypeÅ:ÅotherÅ}","data":{"targetHandle":{"fieldName":"stored_messages","id":"SaveToCSV-UC55G","inputTypes":["Message"],"type":"other"},"sourceHandle":{"dataType":"StoreMessage","id":"StoreMessage-euB6g","name":"stored_messages","output_types":["Message"]}},"selected":false,"className":""},{"source":"FirecrawlScrapeApi-sFYt9","target":"FilterData-gSFhS","sourceHandle":"{ÅdataTypeÅ:ÅFirecrawlScrapeApiÅ,ÅidÅ:ÅFirecrawlScrapeApi-sFYt9Å,ÅnameÅ:ÅdataÅ,Åoutput_typesÅ:[ÅDataÅ]}","targetHandle":"{ÅfieldNameÅ:ÅdataÅ,ÅidÅ:ÅFilterData-gSFhSÅ,ÅinputTypesÅ:[ÅDataÅ],ÅtypeÅ:ÅotherÅ}","id":"reactflow__edge-FirecrawlScrapeApi-sFYt9{ÅdataTypeÅ:ÅFirecrawlScrapeApiÅ,ÅidÅ:ÅFirecrawlScrapeApi-sFYt9Å,ÅnameÅ:ÅdataÅ,Åoutput_typesÅ:[ÅDataÅ]}-FilterData-gSFhS{ÅfieldNameÅ:ÅdataÅ,ÅidÅ:ÅFilterData-gSFhSÅ,ÅinputTypesÅ:[ÅDataÅ],ÅtypeÅ:ÅotherÅ}","data":{"targetHandle":{"fieldName":"data","id":"FilterData-gSFhS","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"FirecrawlScrapeApi","id":"FirecrawlScrapeApi-sFYt9","name":"data","output_types":["Data"]}},"selected":false,"className":""}],"viewport":{"x":-2745.915169556414,"y":-95.05818473518968,"zoom":0.6001044425341676}},"description":"Flow usado para o desafio2 de RAG, para fazer scrapping do site de pontuaÃ§Ã£o, ele recupera os scores do site e salva na memÃ³ria e em um arquivo .csv.","name":"Scrapping_Model","last_tested_version":"1.0.12","endpoint_name":null,"is_component":false}